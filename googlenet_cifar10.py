# -*- coding: utf-8 -*-
"""googlenet_cifar10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13owcWLYtnQ457A-kVMz8jrXFR_KpFYMd
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import sys
import matplotlib
matplotlib.use("Agg")

from sklearn.preprocessing import LabelBinarizer
sys.path.append('/content/drive/My Drive/Colab_Work/PPM/nn/conv')
from minigooglenet import MiniGoogLeNet
sys.path.append('/content/drive/My Drive/Colab_Work/PPM/callbacks')
from trainingmonitor import TrainingMonitor
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import LearningRateScheduler
from keras.optimizers import SGD
from keras.datasets import cifar10
import matplotlib.pyplot as plt
import numpy as np
import argparse
import os

NUM_EPOCHS = 70
INIT_LR = 5e-3

def poly_decay(epoch):
	maxEpochs = NUM_EPOCHS
	baseLR = INIT_LR
	power=1.0

	alpha = baseLR * (1 - (epoch/float(maxEpochs))) ** power
	return float(alpha)

print("[INFO] loading CIFAR-10 data...")

((trainX, trainY), (testX, testY)) = cifar10.load_data()
trainX = trainX.astype("float")
testX = testX.astype("float")

mean = np.mean(trainX, axis=0)
trainX -= mean
testX -= mean

trainY = LabelBinarizer().fit_transform(trainY)
testY = LabelBinarizer().fit_transform(testY)

aug = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1,  
	    horizontal_flip=True, fill_mode="nearest")

print("[INFO] compiling model...")
opt = SGD(lr=INIT_LR, momentum=0.9)
model = MiniGoogLeNet.build(width=32, height=32, depth=3, classes=10)
model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["accuracy"])

callbacks = [LearningRateScheduler(poly_decay)]
print("[INFO] training network...")
H = model.fit_generator(aug.flow(trainX, trainY, batch_size=64),
	    validation_data=(testX, testY), steps_per_epoch=len(trainX)//64, epochs=NUM_EPOCHS, 
	    callbacks=callbacks, verbose=1)

from sklearn.metrics import classification_report
labelNames = ["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"]
print("[INFO] evaluating network...")
predictions = model.predict(testX, batch_size=64)
print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))

# Commented out IPython magic to ensure Python compatibility.
print("[INFO] serializing network...")
# %cd /content/drive/My\ Drive/Colab_Work
model.save("minigooglenet_cifar10.hdf5")
plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0, 70), H.history["loss"], label="train_loss")
plt.plot(np.arange(0, 70), H.history["val_loss"], label="val_loss")
plt.plot(np.arange(0, 70), H.history["acc"], label="train_acc")
plt.plot(np.arange(0, 70), H.history["val_acc"], label="val_acc")
plt.title("Training Loss and Accuracy")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend()
# %cd /content/drive/My\ Drive/Colab_Work
plt.savefig('minigooglenet_cifar10_train_test_plot.png')